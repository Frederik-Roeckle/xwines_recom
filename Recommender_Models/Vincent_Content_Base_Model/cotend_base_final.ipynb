{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-10T15:55:46.636235Z",
     "start_time": "2025-05-10T15:54:31.392169Z"
    },
    "id": "initial_id"
   },
   "source": [
    "# --- Imports ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, FeatureHasher\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from collections import defaultdict # Added\n",
    "from sklearn.metrics import average_precision_score, precision_score, ndcg_score # Added\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wer6_I3RACrp",
    "outputId": "371864c6-fa79-4dc9-ca08-59989d70eb02"
   },
   "id": "wer6_I3RACrp",
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Define your file paths\n",
    "wine_file = '/content/drive/My Drive/XWines_Full_100K_wines.csv'\n",
    "train_file = '/content/drive/My Drive/trainset.csv'\n",
    "test_files = {\n",
    "    'CU_CI': '/content/drive/My Drive/testset_cold_user_cold_item.csv',\n",
    "    'CU_WI': '/content/drive/My Drive/testset_cold_user_warm_item.csv',\n",
    "    'WU_CI': '/content/drive/My Drive/testset_warm_user_cold_item.csv',\n",
    "    'WU_WI': '/content/drive/My Drive/testset_warm_user_warm_item.csv'\n",
    "}\n",
    "drive_save_path = '/content/drive/MyDrive/'\n"
   ],
   "metadata": {
    "id": "zf2LCas2BIlx"
   },
   "id": "zf2LCas2BIlx",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T16:07:22.459093Z",
     "start_time": "2025-05-10T16:06:35.687105Z"
    },
    "id": "fb2d80656ab7cb9e"
   },
   "cell_type": "code",
   "source": [
    "# --- Data Loading ---\n",
    "df_wines = pd.read_csv(wine_file)\n",
    "train_ratings = pd.read_csv(train_file)\n"
   ],
   "id": "fb2d80656ab7cb9e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T16:07:34.601790Z",
     "start_time": "2025-05-10T16:07:34.338467Z"
    },
    "id": "3fcf66ec3510c09a"
   },
   "cell_type": "code",
   "source": [
    "# --- Selecting Wines ONLY from Training Data (avoids leakage) ---\n",
    "# Prepare wines present in training data\n",
    "train_wine_ids = train_ratings['WineID'].unique()\n",
    "df_wines_train = df_wines[df_wines['WineID'].isin(train_wine_ids)].copy().reset_index(drop=True)"
   ],
   "id": "3fcf66ec3510c09a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T16:07:36.343144Z",
     "start_time": "2025-05-10T16:07:36.169783Z"
    },
    "id": "111bd26006741093"
   },
   "cell_type": "code",
   "source": [
    "# --- Text Preprocessing (Lowercase) ---\n",
    "# Standardize all categorical text attributes to lowercase for consistency\n",
    "cols_lowercase = ['WineName', 'Type', 'Elaborate', 'Body', 'Acidity',\n",
    "                  'Country', 'RegionName', 'WineryName']\n",
    "df_wines_train[cols_lowercase] = df_wines_train[cols_lowercase].apply(lambda x: x.str.lower())"
   ],
   "id": "111bd26006741093",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T16:07:40.660071Z",
     "start_time": "2025-05-10T16:07:37.751376Z"
    },
    "id": "9a1d9b51a5c13226"
   },
   "cell_type": "code",
   "source": [
    "# --- List-column Cleaning (Grapes & Harmonize) ---\n",
    "# Clean up columns that represent lists as strings, remove brackets/quotes, and convert to actual Python lists\n",
    "for col in ['Grapes', 'Harmonize']:\n",
    "    df_wines_train[col] = df_wines_train[col].fillna('') \\\n",
    "                         .str.replace(r'[\\[\\]\\']/','',regex=True) \\\n",
    "                         .apply(lambda x: [w.strip().lower() for w in x.split(',') if w.strip()])"
   ],
   "id": "9a1d9b51a5c13226",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T16:07:43.437225Z",
     "start_time": "2025-05-10T16:07:43.424303Z"
    },
    "id": "52c26b0f99d42eae"
   },
   "cell_type": "code",
   "source": [
    "# --- Numeric Preprocessing (ABV) ---\n",
    "# Normalize numerical ABV (alcohol by volume) feature using StandardScaler (mean=0, variance=1)\n",
    "scaler = StandardScaler()\n",
    "df_wines_train['ABV'] = scaler.fit_transform(df_wines_train[['ABV']].astype(float))"
   ],
   "id": "52c26b0f99d42eae",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T16:07:44.624857Z",
     "start_time": "2025-05-10T16:07:44.586262Z"
    },
    "id": "64cc6a35862713d9"
   },
   "cell_type": "code",
   "source": [
    "# --- Preserve original wine data for readable recommendations ---\n",
    "# Save a copy of original wine data attributes for final presentation purposes\n",
    "context_cols=['WineID','WineName','WineryName','Type','Country','RegionName','ABV']\n",
    "df_wines_original = df_wines_train[context_cols].copy()"
   ],
   "id": "64cc6a35862713d9",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T16:07:45.725356Z",
     "start_time": "2025-05-10T16:07:45.460516Z"
    },
    "id": "54db614f2374b6"
   },
   "cell_type": "code",
   "source": [
    "# --- Categorical Features (One-Hot Encoding) ---\n",
    "# Represent categorical variables using one-hot encoding\n",
    "cat_features = ['Type','Elaborate','Body','Acidity','Country']\n",
    "df_wines_train_encoded = pd.get_dummies(df_wines_train,columns=cat_features)"
   ],
   "id": "54db614f2374b6",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T16:07:49.631637Z",
     "start_time": "2025-05-10T16:07:46.679498Z"
    },
    "id": "c4441e0734a230f3"
   },
   "cell_type": "code",
   "source": [
    "# --- TF-IDF Vectorization (Grapes + Harmonize) ---\n",
    "# Create a textual corpus by combining Grapes and Harmonize features\n",
    "corpus = df_wines_train['Grapes'].str.join(' ')+' '+df_wines_train['Harmonize'].str.join(' ')\n",
    "# Vectorize corpus using TF-IDF to capture the uniqueness of terms across wines\n",
    "tfidf_vec = TfidfVectorizer().fit_transform(corpus)"
   ],
   "id": "c4441e0734a230f3",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T16:07:50.484453Z",
     "start_time": "2025-05-10T16:07:50.291721Z"
    },
    "id": "b3fd0a131089ada0"
   },
   "cell_type": "code",
   "source": [
    "# --- Feature hashing (RegionName) ---\n",
    "# Use FeatureHasher to reduce high-cardinality categorical RegionName variable to 16 hashed features\n",
    "hasher = FeatureHasher(n_features=16,input_type='string',alternate_sign=False)\n",
    "hashed_region = hasher.fit_transform(df_wines_train[['RegionName']].values)"
   ],
   "id": "b3fd0a131089ada0",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T16:07:52.272901Z",
     "start_time": "2025-05-10T16:07:51.823227Z"
    },
    "id": "422029c1801ec3d5"
   },
   "cell_type": "code",
   "source": [
    "# --- Combine all features into Sparse Embeddings ---\n",
    "# Identify numeric and encoded categorical features to combine with embeddings\n",
    "non_text_cols = ['ABV'] + [col for col in df_wines_train_encoded if col.startswith(('Type_', 'Elaborate_', 'Body_', 'Acidity_', 'Country_'))]\n",
    "# Convert explicitly to float to ensure correct numeric data types\n",
    "numeric_sparse = csr_matrix(df_wines_train_encoded[non_text_cols].astype(float).values)"
   ],
   "id": "422029c1801ec3d5",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Create a mapping from WineID to its index in the similarity matrix\n",
    "# The order is based on df_wines_train['WineID'] as used for combined_train_sparse\n",
    "wine_id_to_idx = {wine_id: i for i, wine_id in enumerate(df_wines_train['WineID'])}"
   ],
   "metadata": {
    "id": "9xdX9Y6WpyVr"
   },
   "id": "9xdX9Y6WpyVr",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T16:13:01.333576Z",
     "start_time": "2025-05-10T16:12:42.271152Z"
    },
    "id": "677514bd846072"
   },
   "cell_type": "code",
   "source": [
    "combined_train_sparse = hstack([numeric_sparse, tfidf_vec, hashed_region])\n",
    "\n",
    "# --- Compute Similarity Matrix (Training Only) ---\n",
    "# Calculate pairwise cosine similarity among wines based on embeddings\n",
    "similarity_train_np_full = cosine_similarity(combined_train_sparse)\n",
    "# Optimization: Convert to float32 to save memory and potentially speed up operations\n",
    "similarity_matrix_np = similarity_train_np_full.astype(np.float32)\n",
    "del similarity_train_np_full # Free memory of the float64 version"
   ],
   "id": "677514bd846072",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "similarity_df_train = pd.DataFrame(similarity_matrix_np, # Use the float32 version\n",
    "                                   index=df_wines_train['WineID'],\n",
    "                                   columns=df_wines_train['WineID'])"
   ],
   "metadata": {
    "id": "1Q5lFKdht-5X"
   },
   "id": "1Q5lFKdht-5X",
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "global_mean_rating = train_ratings['Rating'].mean()\n",
    "\n",
    "# `user_rated_wines_avg_ratings_idx_map` will store:\n",
    "# { user_id: {wine_idx_in_similarity_matrix: avg_rating} }\n",
    "user_rated_wines_avg_ratings_idx_map = {}\n",
    "\n",
    "# Filter train_ratings to include only wines present in our similarity matrix\n",
    "# (i.e., wines in df_wines_train, which are derived from train_wine_ids)\n",
    "valid_wine_ids_in_sim_matrix = set(wine_id_to_idx.keys())\n",
    "filtered_train_ratings = train_ratings[train_ratings['WineID'].isin(valid_wine_ids_in_sim_matrix)].copy()\n",
    "\n",
    "for user_id, group in tqdm(filtered_train_ratings.groupby('UserID'), desc=\"Preprocessing user ratings\"):\n",
    "    avg_ratings_for_user = group.groupby('WineID')['Rating'].mean()\n",
    "\n",
    "    # Store ratings with wine indices instead of WineIDs for direct use with similarity_matrix_np\n",
    "    ratings_with_indices = {\n",
    "        wine_id_to_idx[wine_id]: rating\n",
    "        for wine_id, rating in avg_ratings_for_user.items()\n",
    "        # wine_id should always be in wine_id_to_idx due to pre-filtering of train_ratings\n",
    "    }\n",
    "    if ratings_with_indices: # Only add user if they have rated wines present in the similarity matrix\n",
    "        user_rated_wines_avg_ratings_idx_map[user_id] = ratings_with_indices"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p9iuHZ_epVxh",
    "outputId": "eb40d810-60a5-4ee4-b88b-430a83939d29"
   },
   "id": "p9iuHZ_epVxh",
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Preprocessing user ratings: 100%|██████████| 1056035/1056035 [06:45<00:00, 2603.81it/s]\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "id": "c4be0ec462b9457a"
   },
   "cell_type": "code",
   "source": [
    "def predict_rating(user_id, target_wine_id,\n",
    "                             user_rated_wines_map, # user_rated_wines_avg_ratings_idx_map\n",
    "                             sim_matrix_np,       # similarity_matrix_np\n",
    "                             wine_id_to_idx_map,  # wine_id_to_idx\n",
    "                             global_mean):\n",
    "\n",
    "    # --- Path for Cold Item ---\n",
    "    # 1. Is the target_wine_id known to our system (i.e., was it in df_wines_train and thus has features and an entry in wine_id_to_idx_map)?\n",
    "    if target_wine_id not in wine_id_to_idx_map:\n",
    "        # If the item is truly \"cold\" (not in wine_id_to_idx_map),\n",
    "        # we have no features for it, so we can't calculate similarities.\n",
    "        return global_mean # THIS IS ONE REASON for CU_CI\n",
    "\n",
    "    # If we reach here, it means target_wine_id *is* in wine_id_to_idx_map.\n",
    "    # This could happen if an item listed as \"cold\" in the test set name\n",
    "    # coincidentally was also present in the training wines.\n",
    "    target_wine_idx = wine_id_to_idx_map[target_wine_id]\n",
    "\n",
    "    # --- Path for Cold User ---\n",
    "    # 2. Does the user_id have any rating history in our training data (i.e., is user_id a key in user_rated_wines_map)?\n",
    "    user_ratings_data = user_rated_wines_map.get(user_id)\n",
    "    if not user_ratings_data:\n",
    "        # For a \"Cold User\" (CU) from testset_cold_user_cold_item.csv,\n",
    "        # this user_id should NOT have any entries in train_ratings.\n",
    "        # Therefore, user_id will not be in user_rated_wines_map.\n",
    "        # user_ratings_data will be None.\n",
    "        return global_mean # THIS IS THE PRIMARY REASON for CU_CI and CU_WI\n",
    "\n",
    "    # --- Path if both user and item are \"warm\" enough to proceed ---\n",
    "    # (The code below is typically NOT reached for CU_CI or CU_WI scenarios)\n",
    "    rated_wine_indices = list(user_ratings_data.keys())\n",
    "    if not rated_wine_indices: # Should ideally not happen if user_ratings_data is not None\n",
    "        return global_mean\n",
    "\n",
    "    actual_ratings_for_these_indices = np.array([user_ratings_data[idx] for idx in rated_wine_indices], dtype=np.float32)\n",
    "    # Get similarities: sim_matrix_np[target_wine_idx] is the row for target_wine_id\n",
    "    # sim_matrix_np[target_wine_idx, rated_wine_indices] gets specific similarities\n",
    "    item_similarities = sim_matrix_np[target_wine_idx, rated_wine_indices] # This is already np.float32\n",
    "    sim_sum_abs = np.sum(np.abs(item_similarities))\n",
    "\n",
    "    if sim_sum_abs == 0: # User's rated items are not similar to target item\n",
    "        return global_mean\n",
    "\n",
    "    weighted_sum = np.dot(actual_ratings_for_these_indices, item_similarities)\n",
    "    return weighted_sum / sim_sum_abs"
   ],
   "id": "c4be0ec462b9457a",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "id": "49e39d51a1ef568d"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 19,
   "source": [
    "def measures_at_k(predictions_data, k=10, threshold=3.5):\n",
    "    \"\"\"Return precision and nDCG at k metrics averaged across all users\"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    # predictions_data is expected to be a list of tuples: (uid, iid, true_r, est, _)\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions_data: # iid (item_id) is ignored by _\n",
    "        user_est_true[uid].append((est, true_r)) # Store (predicted_rating, true_rating)\n",
    "\n",
    "    average_precisions = dict()\n",
    "    precisions_at_k = dict()\n",
    "    ndcgs_at_k = dict()\n",
    "\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        # Sort user ratings by estimated value (predicted_rating)\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Create y_true (binary based on threshold) and y_pred (binary based on threshold)\n",
    "        # for precision-based metrics\n",
    "        y_true_binary = [1 if (true_r >= threshold) else 0 for (_, true_r) in user_ratings]\n",
    "        y_pred_binary = [1 if (est_r >= threshold) else 0 for (est_r, _) in user_ratings]\n",
    "\n",
    "        # Raw scores for nDCG and some versions of AP\n",
    "        actual_scores_raw = [true_r for (_, true_r) in user_ratings]\n",
    "        predicted_scores_raw = [est_r for (est_r, _) in user_ratings]\n",
    "\n",
    "\n",
    "        # Average Precision\n",
    "        if sum(y_true_binary) > 0: # Check if there are any relevant items for the user\n",
    "            # Using y_pred_binary as per user's snippet for AP's y_score argument.\n",
    "            # A more common approach is to use predicted_scores_raw for the y_score argument.\n",
    "            average_precisions[uid] = average_precision_score(y_true_binary, y_pred_binary)\n",
    "        else:\n",
    "            average_precisions[uid] = 0.0 # Or np.nan, or handle as per preference\n",
    "\n",
    "        # Precision@k\n",
    "        # y_true_binary_at_k and y_pred_binary_at_k correspond to items sorted by predicted score\n",
    "        y_true_binary_at_k = y_true_binary[:k]\n",
    "        y_pred_binary_at_k = y_pred_binary[:k]\n",
    "\n",
    "        precisions_at_k[uid] = precision_score(y_true_binary_at_k, y_pred_binary_at_k, zero_division=0)\n",
    "\n",
    "        # nDCG@k\n",
    "        # Uses raw true scores and raw predicted scores.\n",
    "        # Items are already sorted by predicted_scores_raw due to `user_ratings.sort`.\n",
    "        if not user_ratings: # Handle empty user_ratings if it can occur\n",
    "             ndcgs_at_k[uid] = 0.0\n",
    "        elif len(user_ratings) == 1 and k > 0 : # User's custom handling for single item\n",
    "            # This custom nDCG for single item: 1 if (relevant and predicted relevant), else 0\n",
    "            est, true_r = user_ratings[0]\n",
    "            ndcgs_at_k[uid] = 1.0 if ((true_r >= threshold) and (est >= threshold)) else 0.0\n",
    "        else:\n",
    "            # Standard ndcg_score expects 2D arrays for y_true and y_score if passing single sample\n",
    "            ndcgs_at_k[uid] = ndcg_score(np.asarray([actual_scores_raw]), np.asarray([predicted_scores_raw]), k=k)\n",
    "\n",
    "    # Compute simple averages over all users for each score (moved outside the loop)\n",
    "    if not user_est_true: # No users or no predictions\n",
    "        avg_average_precisions = 0.0\n",
    "        avg_precisions_at_k = 0.0\n",
    "        avg_ndcgs_at_k = 0.0\n",
    "    else:\n",
    "        avg_average_precisions = sum(val for val in average_precisions.values()) / len(average_precisions) if average_precisions else 0.0\n",
    "        avg_precisions_at_k = sum(val for val in precisions_at_k.values()) / len(precisions_at_k) if precisions_at_k else 0.0\n",
    "        avg_ndcgs_at_k = sum(val for val in ndcgs_at_k.values()) / len(ndcgs_at_k) if ndcgs_at_k else 0.0\n",
    "\n",
    "    return avg_average_precisions, avg_precisions_at_k, avg_ndcgs_at_k"
   ],
   "id": "49e39d51a1ef568d"
  },
  {
   "cell_type": "code",
   "source": [
    "batch_size = 100000 # Adjust batch size according to your requirements\n"
   ],
   "metadata": {
    "id": "5NuKhyP50Vkk"
   },
   "id": "5NuKhyP50Vkk",
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def evaluate_in_batches_optimized(test_ratings_df,\n",
    "                                  user_ratings_map_param,\n",
    "                                  sim_matrix_param,\n",
    "                                  wine_id_idx_map_param,\n",
    "                                  global_mean_param,\n",
    "                                  batch_size_param,\n",
    "                                  scenario_name,\n",
    "                                  ranking_k=5,  # Parameter for @k metrics\n",
    "                                  ranking_threshold=3.5):  # Parameter for relevance threshold\n",
    "\n",
    "    y_true_list, y_pred_list, rating_ids_list = [], [], []\n",
    "    all_predictions_for_ranking = []  # To store (uid, iid, true_r, est, _) for ranking metrics\n",
    "\n",
    "    num_batches = (len(test_ratings_df) + batch_size_param - 1) // batch_size_param\n",
    "\n",
    "    for i in tqdm(range(num_batches), desc=f\"Evaluating {scenario_name}\"):\n",
    "        start_idx = i * batch_size_param\n",
    "        end_idx = min((i + 1) * batch_size_param, len(test_ratings_df))\n",
    "        batch_df = test_ratings_df.iloc[start_idx:end_idx]\n",
    "\n",
    "        current_preds_batch = []\n",
    "        current_true_batch = batch_df.Rating.tolist()\n",
    "\n",
    "        for user_id_val, wine_id_val, true_rating_val in zip(batch_df.UserID, batch_df.WineID, current_true_batch):\n",
    "            pred = predict_rating(user_id_val, wine_id_val,\n",
    "                                            user_ratings_map_param,\n",
    "                                            sim_matrix_param,\n",
    "                                            wine_id_idx_map_param,\n",
    "                                            global_mean_param)\n",
    "            current_preds_batch.append(pred)\n",
    "            # Store for ranking metrics: (uid, iid, true_r, est, details=None)\n",
    "            all_predictions_for_ranking.append((user_id_val, wine_id_val, true_rating_val, pred, None))\n",
    "\n",
    "        y_true_list.extend(current_true_batch)\n",
    "        y_pred_list.extend(current_preds_batch)\n",
    "        rating_ids_list.extend(batch_df.RatingID.tolist())\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_true_list, y_pred_list))\n",
    "    mae = mean_absolute_error(y_true_list, y_pred_list)\n",
    "\n",
    "    predictions_output_df = pd.DataFrame({'RatingID': rating_ids_list, 'PredictedRating': y_pred_list})\n",
    "    predictions_output_df.to_csv(f'{drive_save_path}predictions_{scenario_name}_optimized.csv', index=False)\n",
    "\n",
    "    print(f\"\\n--- Results for {scenario_name} ---\")\n",
    "    print(f\"RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
    "\n",
    "    # Calculate and print ranking metrics\n",
    "    if all_predictions_for_ranking:\n",
    "        avg_ap, avg_p_at_k, avg_ndcg_at_k = measures_at_k(\n",
    "            all_predictions_for_ranking,\n",
    "            k=ranking_k,\n",
    "            threshold=ranking_threshold\n",
    "        )\n",
    "        print(f'Avg. AveragePrecision: {avg_ap:.4f}')\n",
    "        print(f'Avg. Precision@{ranking_k}: {avg_p_at_k:.4f}')\n",
    "        print(f'Avg. nDCG@{ranking_k}: {avg_ndcg_at_k:.4f}')\n",
    "    else:\n",
    "        print(\"No predictions made, skipping ranking metrics.\")\n",
    "        avg_ap, avg_p_at_k, avg_ndcg_at_k = 0.0, 0.0, 0.0\n",
    "\n",
    "    return rmse, mae, avg_ap, avg_p_at_k, avg_ndcg_at_k\n",
    "\n",
    "\n",
    "all_results = {}\n",
    "for scenario, test_file_path in test_files.items():\n",
    "    current_test_ratings = pd.read_csv(test_file_path)\n",
    "    rmse_val, mae_val, avg_ap_val, avg_p_at_k_val, avg_ndcg_at_k_val = evaluate_in_batches_optimized(\n",
    "        current_test_ratings,\n",
    "        user_rated_wines_avg_ratings_idx_map,\n",
    "        similarity_matrix_np,\n",
    "        wine_id_to_idx,\n",
    "        global_mean_rating,\n",
    "        batch_size,\n",
    "        scenario,\n",
    "        ranking_k=5,  # Using k=5 as in your example\n",
    "        ranking_threshold=3.5  # Using threshold=3.5 as in your example\n",
    "    )\n",
    "    all_results[scenario] = {\n",
    "        'RMSE': rmse_val, 'MAE': mae_val,\n",
    "        'Avg. AP': avg_ap_val, f'Avg. P@5': avg_p_at_k_val, f'Avg. nDCG@5': avg_ndcg_at_k_val\n",
    "    }"
   ],
   "metadata": {
    "id": "NluVIeuB7Mu6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3b491752-c2af-4e36-a3f2-f966c0eeb890"
   },
   "id": "NluVIeuB7Mu6",
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Evaluating CU_CI: 100%|██████████| 1/1 [00:00<00:00, 112.02it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "--- Results for CU_CI ---\n",
      "RMSE: 0.8220, MAE: 0.6164\n",
      "Avg. AveragePrecision: 0.7089\n",
      "Avg. Precision@5: 0.7088\n",
      "Avg. nDCG@5: 0.7283\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Evaluating CU_WI: 100%|██████████| 6/6 [00:05<00:00,  1.04it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "--- Results for CU_WI ---\n",
      "RMSE: 1.0739, MAE: 0.6958\n",
      "Avg. AveragePrecision: 0.8134\n",
      "Avg. Precision@5: 0.6968\n",
      "Avg. nDCG@5: 0.9253\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Evaluating WU_CI: 100%|██████████| 1/1 [00:00<00:00, 50.51it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "--- Results for WU_CI ---\n",
      "RMSE: 0.6852, MAE: 0.5062\n",
      "Avg. AveragePrecision: 0.8389\n",
      "Avg. Precision@5: 0.8389\n",
      "Avg. nDCG@5: 0.8651\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Evaluating WU_WI: 100%|██████████| 21/21 [00:48<00:00,  2.33s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "--- Results for WU_WI ---\n",
      "RMSE: 0.7951, MAE: 0.5383\n",
      "Avg. AveragePrecision: 0.8808\n",
      "Avg. Precision@5: 0.7796\n",
      "Avg. nDCG@5: 0.8896\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "for scenario, metrics in all_results.items():\n",
    "    print(f\"\\nScenario: {scenario}\")\n",
    "    for metric_name, metric_value in metrics.items():\n",
    "        print(f\"{metric_name}: {metric_value:.4f}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M48egcnEpNCp",
    "outputId": "52e98594-c5b1-42cf-9c40-0f7a7147d375"
   },
   "id": "M48egcnEpNCp",
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Scenario: CU_CI\n",
      "RMSE: 0.8220\n",
      "MAE: 0.6164\n",
      "Avg. AP: 0.7089\n",
      "Avg. P@5: 0.7088\n",
      "Avg. nDCG@5: 0.7283\n",
      "\n",
      "Scenario: CU_WI\n",
      "RMSE: 1.0739\n",
      "MAE: 0.6958\n",
      "Avg. AP: 0.8134\n",
      "Avg. P@5: 0.6968\n",
      "Avg. nDCG@5: 0.9253\n",
      "\n",
      "Scenario: WU_CI\n",
      "RMSE: 0.6852\n",
      "MAE: 0.5062\n",
      "Avg. AP: 0.8389\n",
      "Avg. P@5: 0.8389\n",
      "Avg. nDCG@5: 0.8651\n",
      "\n",
      "Scenario: WU_WI\n",
      "RMSE: 0.7951\n",
      "MAE: 0.5383\n",
      "Avg. AP: 0.8808\n",
      "Avg. P@5: 0.7796\n",
      "Avg. nDCG@5: 0.8896\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "id": "6b41d6aadddc4991"
   },
   "cell_type": "code",
   "source": [
    "# --- Recommendation (Item-to-Item) ---\n",
    "# Function recommending similar wines based on cosine similarity scores\n",
    "def get_recommendation(wine_id_param, sim_df, wines_original_df, num_recs=5):\n",
    "    if wine_id_param not in sim_df.index: # Check if wine is in our similarity matrix\n",
    "        print(f\"WineID {wine_id_param} not found in the similarity matrix.\")\n",
    "        return pd.DataFrame() # Return empty DataFrame if not found\n",
    "\n",
    "    # Get similarity scores for the given wine_id, sort them, drop the wine itself, and take top N\n",
    "    similar_wines_series = sim_df[wine_id_param].sort_values(ascending=False).drop(wine_id_param).head(num_recs)\n",
    "    similar_wines_df = similar_wines_series.reset_index()\n",
    "    similar_wines_df.columns = ['WineID', 'Similarity']\n",
    "\n",
    "    # Merge with original wine details to make recommendations readable\n",
    "    recommendations_df = pd.merge(similar_wines_df, wines_original_df[['WineID', 'WineName', 'Type', 'Country']], on='WineID', how='left')\n",
    "    return recommendations_df\n"
   ],
   "id": "6b41d6aadddc4991",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "id": "47371f6994c8cb1e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4ec9d63b-7498-49c5-cc0c-318af5e48059"
   },
   "cell_type": "code",
   "source": [
    "# Example usage of function: Provide similar wines for user-selected wine\n",
    "example_wine_id_val = train_ratings['WineID'].iloc[0]\n",
    "recommendations_result = get_recommendation(example_wine_id_val, similarity_df_train, df_wines_original)\n",
    "print(f\"\\nItem-to-item recommendations for WineID{example_wine_id_val}:\\n{recommendations_result}\")"
   ],
   "id": "47371f6994c8cb1e",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Item-to-item recommendations for WineID136168:\n",
      "   WineID  Similarity                                           WineName Type  \\\n",
      "0  136255         1.0                             brunello di montalcino  red   \n",
      "1  135927         1.0                             brunello di montalcino  red   \n",
      "2  142393         1.0                             brunello di montalcino  red   \n",
      "3  136716         1.0           leonardo da vinci brunello di montalcino  red   \n",
      "4  153633         1.0  tenuta greppone mazzi riserva brunello di mont...  red   \n",
      "\n",
      "  Country  \n",
      "0   italy  \n",
      "1   italy  \n",
      "2   italy  \n",
      "3   italy  \n",
      "4   italy  \n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "id": "3fbff6472b7df25"
   },
   "cell_type": "code",
   "source": [
    "# --- Popular Wines utility (Cold-Start Recommendations) ---\n",
    "# Identify most popular/highly-rated wines in training data, useful for cold-start recommendations\n",
    "def popular_wines(train_ratings_df, wines_original_df, n_recs=5, min_ratings_thresh=10):\n",
    "    # Group by WineID and calculate mean rating and count of ratings\n",
    "    popular_df = train_ratings_df.groupby('WineID')['Rating'].agg(['mean', 'count'])\n",
    "    # Filter out wines with fewer than min_ratings_thresh ratings\n",
    "    popular_df = popular_df[popular_df['count'] >= min_ratings_thresh]\n",
    "    # Sort by mean rating in descending order and take top N\n",
    "    popular_df = popular_df.sort_values('mean', ascending=False).head(n_recs)\n",
    "\n",
    "    # Merge with original wine details for readability\n",
    "    # use .loc to select rows from wines_original_df whose WineID is in popular_df.index\n",
    "    # and then select specific columns.\n",
    "    popular_recs_df = wines_original_df[wines_original_df['WineID'].isin(popular_df.index)].copy()\n",
    "    # To maintain the order from popular_df, we can reindex or merge and sort\n",
    "    popular_recs_df = popular_recs_df.set_index('WineID').loc[popular_df.index].reset_index()\n",
    "\n",
    "    return popular_recs_df[['WineID', 'WineName', 'Type', 'Country']] # Include WineName"
   ],
   "id": "3fbff6472b7df25",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "id": "38a347cb87a943e6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "603a4f83-7dff-4970-c88e-1cd6f364856c"
   },
   "cell_type": "code",
   "source": [
    "# Display example popular wine recommendations\n",
    "popular=popular_wines(train_ratings,df_wines_original)\n",
    "print(f\"Popular wines for cold-start recommendations:\\n{popular}\")"
   ],
   "id": "38a347cb87a943e6",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Popular wines for cold-start recommendations:\n",
      "   WineID                                           WineName       Type  \\\n",
      "0  183447                          wraith cabernet sauvignon        red   \n",
      "1  117346      clos d'ambonnay blanc de noirs brut champagne  sparkling   \n",
      "2  188413                                       jusqu'a l'os        red   \n",
      "3  183348  cabernet sauvignon old sparky beckstoffer to k...        red   \n",
      "4  122521                                 cristal vinothèque  sparkling   \n",
      "\n",
      "         Country  \n",
      "0  united states  \n",
      "1         france  \n",
      "2  united states  \n",
      "3  united states  \n",
      "4         france  \n"
     ]
    }
   ],
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "V28",
   "machine_shape": "hm"
  },
  "accelerator": "TPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc02e9e6",
   "metadata": {},
   "source": [
    "# Hybrid recommender\n",
    "## Collaborative filtering + Content-Based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcf1f93",
   "metadata": {},
   "source": [
    "## Plan:\n",
    "* Load and merge the wines metadata on WineID.\n",
    "* Load the data, format columns to the correct types like:\n",
    "    * Grapes and Harmonize (string list) -> (python list)  \n",
    "    !!! This step is required in future always when loading this columns from csv.\n",
    "    * Vintage (str) -> numeric. I just simply replace N.V.(non-vintage) with 0 and then turn whole column to integer type.\n",
    "    * Datetime to a proper pd.datetime type\n",
    "* Columns used:\n",
    "    * **WineID**: Integer. The wine primary key identification;\n",
    "    * **WineName**: String. The textual wine identification presented in the label;\n",
    "    * **Type**: String. The categorical type classification: Red, white or rosé for still wines, gasified sparkling or dessert for sweeter and fortified wines. Dessert/Port is a subclassification for liqueur dessert wines;\n",
    "    * **Elaborate**: String. Categorical classification between varietal or assemblage/blend. The most famous blends are also considered, such as * Bordeaux red and white blend, Valpolicella blend and Portuguese red and white blend;\n",
    "    * **Grapes**: String list. It contains the grape varieties used in the wine elaboration. The original names found have been kept;\n",
    "    * **Harmonize**: String list. It contains the main dishes set that pair with the wine item. These are provided by producers but openly recommended on the internet by sommeliers and even consumers;\n",
    "    * **ABV**: Float. The alcohol by volume (ABV) percentage. According to [1], the value shown on the label may vary, and a tolerance of 0.5% per 100 volume is allowed, reaching 0.8% for some wines;\n",
    "    * **Body**: String. The categorical body classification: Very light-bodied, light-bodied, medium-bodied, full-bodied or very full-bodied based on wine viscosity [37];\n",
    "    * **Acidity**: String. The categorical acidity classification: Low, medium, or high, based on potential hydrogen (pH) score [38];\n",
    "    * **Country**: String. The categorical origin country identification of the wine production (ISO-3166);\n",
    "    * **RegionName**: String. The textual wine region identification. The appellation region name was retained when identified;\n",
    "    * **WineryName**: String. The textual winery identification;\n",
    "    * **UserID**: Integer. The sequential key without identifying the user's private data;\n",
    "    * **Vintage**: String. A rated vintage year or the abbreviation \"N.V.\" referring to \"non-vintage\";\n",
    "    * **Date**: String. Datetime in the format YYYY-MM-DD hh:mm:ss informing when it was rated by the user. It can be easily converted to other formats.\n",
    "    * **Rating**(**Target variable**): Float. It contains the 5-stars (1–5) rating value ⊂ {1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5} performed by the user;\n",
    "* Columns dropped:\n",
    "    * **RegionID** - since it is just unique IDs and not descriptive for the recommender.\n",
    "    * **Code** - since it's the same meaning as **Country** column. Either one can be selected.\n",
    "    * **Vintages** - since it's just lists of possible vintages and we already have a Vintage column with the exact value(year or 0 for non-vintage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8ee3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "# Training and evaluation\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, root_mean_squared_error\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from category_encoders import TargetEncoder, HashingEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from scipy.sparse import hstack, csr_matrix, issparse, lil_matrix, save_npz, load_npz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dcacaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter of string lists into Python lists\n",
    "# (e.g. \"['a', 'b', 'c']\" → [a, b, c])\n",
    "def parse_list_col(s):\n",
    "    return ast.literal_eval(s)\n",
    "\n",
    "# Converter of 'N.V.' to 0, so column is numeric\n",
    "def parse_vintage(s):\n",
    "    return 0 if s == 'N.V.' else int(s)\n",
    "\n",
    "\n",
    "base_path = '..\\..\\..\\..\\data\\main'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd42175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train and test splits\n",
    "\n",
    "wines = pd.read_csv(\n",
    "    f'{base_path}\\\\XWines_Full_100K_wines.csv', \n",
    "    usecols=['WineID', 'Type', 'Elaborate', 'ABV', 'Body', 'Acidity', 'RegionName', 'WineryName', 'Grapes','Harmonize','Country'],\n",
    "    converters={\n",
    "        'Grapes':    parse_list_col,\n",
    "        'Harmonize': parse_list_col\n",
    "    }\n",
    ")\n",
    "train = pd.read_csv(\n",
    "    f'{base_path}\\\\trainset.csv', \n",
    "    usecols=['UserID', 'WineID', 'Rating', 'Date', 'Vintage'],\n",
    "    parse_dates=['Date'],\n",
    "    date_format=lambda s: pd.to_datetime(s),\n",
    "    converters={'Vintage': parse_vintage}\n",
    ")\n",
    "test_uwarm_iwarm = pd.read_csv(\n",
    "    f'{base_path}\\\\testset_warm_user_warm_item.csv', \n",
    "    usecols=['RatingID', 'UserID', 'WineID', 'Rating', 'Date', 'Vintage'],\n",
    "    parse_dates=['Date'],\n",
    "    date_format=lambda s: pd.to_datetime(s),\n",
    "    converters={'Vintage': parse_vintage}\n",
    ")\n",
    "test_uwarm_icold = pd.read_csv(\n",
    "    f'{base_path}\\\\testset_warm_user_cold_item.csv', \n",
    "    usecols=['RatingID', 'UserID', 'WineID', 'Rating', 'Date', 'Vintage'],\n",
    "    parse_dates=['Date'],\n",
    "    date_format=lambda s: pd.to_datetime(s),\n",
    "    converters={'Vintage': parse_vintage}\n",
    ")\n",
    "test_ucold_iwarm = pd.read_csv(\n",
    "    f'{base_path}\\\\testset_cold_user_warm_item.csv', \n",
    "    usecols=['RatingID', 'UserID', 'WineID', 'Rating', 'Date', 'Vintage'],\n",
    "    parse_dates=['Date'],\n",
    "    date_format=lambda s: pd.to_datetime(s),\n",
    "    converters={'Vintage': parse_vintage}\n",
    ")\n",
    "test_ucold_icold = pd.read_csv(\n",
    "    f'{base_path}\\\\testset_cold_user_cold_item.csv', \n",
    "    usecols=['RatingID', 'UserID', 'WineID', 'Rating', 'Date', 'Vintage'],\n",
    "    parse_dates=['Date'],\n",
    "    date_format=lambda s: pd.to_datetime(s),\n",
    "    converters={'Vintage': parse_vintage}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532745ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ratings with wines metadata on 'WineID'\n",
    "train = train.merge(wines, on='WineID', how='left')\n",
    "test_uwarm_iwarm = test_uwarm_iwarm.merge(wines, on='WineID', how='left')\n",
    "test_uwarm_icold = test_uwarm_icold.merge(wines, on='WineID', how='left')\n",
    "test_ucold_iwarm = test_ucold_iwarm.merge(wines, on='WineID', how='left')\n",
    "test_ucold_icold = test_ucold_icold.merge(wines, on='WineID', how='left')\n",
    "\n",
    "# Check the shapes\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test warm user warm item shape: {test_uwarm_iwarm.shape}\")\n",
    "print(f\"Test warm user cold item shape: {test_uwarm_icold.shape}\")\n",
    "print(f\"Test cold user warm item shape: {test_ucold_iwarm.shape}\")\n",
    "print(f\"Test cold user cold item shape: {test_ucold_icold.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fbf443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a small sample of the training set\n",
    "# train = train.sample(frac=0.1, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12386489",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "### Preprocessing methods for different features:\n",
    "* **Standard Scaler** - is used for numerical type columns\n",
    "    * **ABV**\n",
    "    * **Vintage** (formatted to be numerical)\n",
    "    * **DaysAgo(Date)** - see below\n",
    "* **One-hot-encoding** - is used for categorical features, but is limited by the number of categories within a feature:\n",
    "    * **Type**\n",
    "    * **Body**\n",
    "    * **Acidity**\n",
    "    * **Elaborate**\n",
    "* **Multi-Label** - is used for categorical features with too many categories, where also multiple active categories could be possible:\n",
    "    * **Grapes** (774 classes)\n",
    "    * **Harmonize** (~64 classes)\n",
    "* **Target Encoding** - used for text features and user IDs, wine IDs. Used with KFold(5 folds) to prevent data leakage, i.e. encoded feature never knows about it's own target value\n",
    "* **Date encoding** - created custom object to convert datetime column to DaysAgo from the most recent record column. This way we keep information about time-related information and reduce feature to be simply numerical. **Standard Scaler** applied afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f793f2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate features\n",
    "\n",
    "# Use StandardScaler for numerical features (create binary Is_NonVintage column derived from Vintage and maybe fill NaN values with 0)\n",
    "numerical_features = ['ABV', 'Vintage']\n",
    "# Use one-hot encoding for categorical features\n",
    "categorical_features = ['Type', 'Elaborate', 'Body', 'Acidity']\n",
    "# Use multilabel binarizer for multilabel features\n",
    "multilabel_features = ['Grapes', 'Harmonize']\n",
    "# Use target encoding for Country\n",
    "targetencoder_features = ['Country']\n",
    "# Use frequency encoder for IDs and high cardinality features\n",
    "frequency_features = ['WineID', 'UserID', 'WineryName', 'RegionName']\n",
    "# Use conversion to DaysAgo for time-based features\n",
    "date_features = ['Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9ad16f",
   "metadata": {},
   "source": [
    "* **Create Preprocessing pipeline**:\n",
    "    ##### **Important**: Since during Grapes column encoding we create 774 classes + there are around 100 classes from other encoders, the pandas DataFrame would require too much RAM (I recieved 69GB memory allocation error only for the Grapes column) and same happening for the dense array (numpy), I used csr_matrix from scipy.sparse and some additional optimizations for MultiLabelBinarizer in particular, to be able to store all the preprocessed features. More info in code below.\n",
    "\n",
    "    * **Created custom object for Date column preprocessing**\n",
    "    * **Created Wrappers for other preprocessors to always return sparse csr matricies**. For OneHotEncoding there is already implemented sparse output. For StandardScaler in date_pipeline wrapper is not required, since the input is already a csr matrix.\n",
    "    * **Created pipelines for each preprocessor and a general pipeline to combine everything together, using ColumnTransformer** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075e413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date preprocessor\n",
    "class DateTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Transforms a single datetime column into 'days ago' relative to the latest date in training data.\"\"\"\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # Expect a DataFrame with a single datetime column\n",
    "        self.col = X.columns[0]\n",
    "        self.column = f\"{self.col}_days_ago\"\n",
    "        self.reference_date = pd.to_datetime(X[self.col]).max()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        days_ago = (self.reference_date - pd.to_datetime(X[self.col])).dt.days\n",
    "        \n",
    "        return csr_matrix(days_ago.values.reshape(-1, 1))\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return np.array([self.column])\n",
    "    \n",
    "\n",
    "class MultiLabelWrapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.encoders = {}\n",
    "        self.feature_names = []\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.feature_names = []\n",
    "        for col in X.columns:\n",
    "            mlb = MultiLabelBinarizer()\n",
    "            # Fill missing with empty list for consistent fitting\n",
    "            safe_col = X[col].apply(lambda x: x if isinstance(x, list) else [])\n",
    "            mlb.fit(safe_col)\n",
    "            self.encoders[col] = mlb\n",
    "            self.feature_names.extend([f\"{col}__{cls}\" for cls in mlb.classes_])\n",
    "        return self\n",
    "            \n",
    "    def transform(self, X):\n",
    "        matricies = []\n",
    "        for col in X.columns:\n",
    "            mlb = self.encoders[col]\n",
    "            class_index = {cls: i for i, cls in enumerate(mlb.classes_)}\n",
    "            n_rows = len(X)\n",
    "            n_classes = len(mlb.classes_)\n",
    "            sparse = lil_matrix((n_rows, n_classes), dtype=np.uint8)\n",
    "\n",
    "            for i, labels in enumerate(X[col]):\n",
    "                # Handle missing or malformed entries\n",
    "                if not isinstance(labels, list):\n",
    "                    labels = []\n",
    "                for label in labels:\n",
    "                    if label in class_index:\n",
    "                        sparse[i, class_index[label]] = 1\n",
    "\n",
    "            matricies.append(sparse.tocsr())\n",
    "        return hstack(matricies, format='csr')\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return np.array(self.feature_names)\n",
    "\n",
    "\n",
    "class TargetEncoderWrapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.encoders = {}\n",
    "        self.feature_names = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.feature_names = []\n",
    "        self.global_means = {}\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        for col in X.columns:\n",
    "            te = TargetEncoder(cols=[col])\n",
    "            te.fit(X[[col]], y, cv=kf)\n",
    "            self.encoders[col] = te\n",
    "            self.global_means[col] = y.mean() \n",
    "            self.feature_names.append(f'{col}_target_encoded')\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        matricies = []\n",
    "        for col in X.columns:\n",
    "            te = self.encoders[col]\n",
    "            df_encoded = te.transform(X[[col]])\n",
    "            arr = df_encoded[col].fillna(self.global_means[col]).values.reshape(-1, 1)\n",
    "            matricies.append(csr_matrix(arr))\n",
    "        return hstack(matricies, format='csr')\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return np.array(self.feature_names)\n",
    "    \n",
    "    \n",
    "class FrequencyEncoderWrapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.freq_maps = {}\n",
    "        self.feature_names = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.freq_maps = {}\n",
    "        self.feature_names = [f\"{col}_freq\" for col in X.columns]\n",
    "        for col in X.columns:\n",
    "            self.freq_maps[col] = X[col].value_counts(normalize=True).to_dict()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        matrices = []\n",
    "        for col in X.columns:\n",
    "            freq = X[col].map(self.freq_maps[col]).fillna(0).values.reshape(-1, 1)\n",
    "            matrices.append(csr_matrix(freq))\n",
    "        return hstack(matrices, format='csr')\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return np.array(self.feature_names)\n",
    "\n",
    "\n",
    "class StandardScalerWrapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler(with_mean=False)\n",
    "        self.feature_names = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.feature_names = X.columns.tolist()\n",
    "        self.scaler.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        # Always return sparse csr_matrix\n",
    "        if not issparse(X_scaled):\n",
    "            X_scaled = csr_matrix(X_scaled)\n",
    "        return X_scaled\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return np.array(self.feature_names)\n",
    "\n",
    "## Preprocessing pipeline\n",
    "\n",
    "# Numerical\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('scaler', StandardScalerWrapper()),\n",
    "    ])\n",
    "\n",
    "# Categorical via one-hot-encoding\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=True))\n",
    "])\n",
    "\n",
    "\n",
    "# Categorical via MultiLabelBinarizer\n",
    "multilabel_pipeline = Pipeline([\n",
    "    ('multilabel', MultiLabelWrapper())\n",
    "])\n",
    "\n",
    "# Country via target encoding\n",
    "target_pipeline = Pipeline([\n",
    "    ('target', TargetEncoderWrapper())\n",
    "])\n",
    "\n",
    "# High cardinality categorical features via frequency encoding\n",
    "# (i.e. WineryName, RegionName, UserID, WineID)\n",
    "frequency_pipeline = Pipeline([\n",
    "    ('frequency', FrequencyEncoderWrapper())\n",
    "])\n",
    "\n",
    "# Datetime via custom date transformer\n",
    "date_pipeline = Pipeline([\n",
    "    ('date', DateTransformer()),\n",
    "    ('scaler', StandardScaler(with_mean=False))\n",
    "])\n",
    "\n",
    "# Preprocessor\n",
    "# Remainnder contains RatingID column, which is not needed for training neither for testing\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('numerical', numerical_pipeline, numerical_features),\n",
    "    ('categorical', categorical_pipeline, categorical_features),\n",
    "    ('multilabel', multilabel_pipeline, multilabel_features),\n",
    "    ('target', target_pipeline, targetencoder_features),\n",
    "    ('frequency', frequency_pipeline, frequency_features),\n",
    "    ('date', date_pipeline, date_features)\n",
    "], remainder='drop')\n",
    "\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b82d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop target column for all datasets\n",
    "\n",
    "X_train = train.drop(columns=['Rating'])\n",
    "y_train = train['Rating']\n",
    "\n",
    "X_test_uwarm_iwarm = test_uwarm_iwarm.drop(columns=['Rating'])\n",
    "y_test_uwarm_iwarm = test_uwarm_iwarm['Rating']\n",
    "\n",
    "X_test_uwarm_icold = test_uwarm_icold.drop(columns=['Rating'])\n",
    "y_test_uwarm_icold = test_uwarm_icold['Rating']\n",
    "\n",
    "X_test_ucold_iwarm = test_ucold_iwarm.drop(columns=['Rating'])\n",
    "y_test_ucold_iwarm = test_ucold_iwarm['Rating']\n",
    "\n",
    "X_test_ucold_icold = test_ucold_icold.drop(columns=['Rating'])\n",
    "y_test_ucold_icold = test_ucold_icold['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfceeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Train/val split for hyperparameter tuning\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c89777",
   "metadata": {},
   "source": [
    "* **Fit preprocessing pipeline on training data. We pass target variable there for the Target Encoder**\n",
    "* **Transform train and test sets on a fitted preprocessor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732a405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the preprocessing pipeline\n",
    "preprocessing_pipeline.fit(X_train, y_train)\n",
    "\n",
    "X_train_transformed = preprocessing_pipeline.transform(X_train)\n",
    "X_val_transformed = preprocessing_pipeline.transform(X_val)\n",
    "X_test_uwarm_iwarm_transformed = preprocessing_pipeline.transform(X_test_uwarm_iwarm)\n",
    "X_test_uwarm_icold_transformed = preprocessing_pipeline.transform(X_test_uwarm_icold)\n",
    "X_test_ucold_iwarm_transformed = preprocessing_pipeline.transform(X_test_ucold_iwarm)\n",
    "X_test_ucold_icold_transformed = preprocessing_pipeline.transform(X_test_ucold_icold)\n",
    "\n",
    "# Save feature names\n",
    "feature_names = preprocessing_pipeline.get_feature_names_out()\n",
    "# Check the size of feature names and transformed data features \n",
    "print(f\"Feature names size: {len(feature_names)}\")\n",
    "print(f\"Transformed train data size: {X_train_transformed.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7647c97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save transformed data to npz\n",
    "save_npz(f'{base_path}\\\\preprocessed\\\\X_train_transformed.npz', X_train_transformed)\n",
    "save_npz(f'{base_path}\\\\preprocessed\\\\X_val_transformed.npz', X_val_transformed)\n",
    "save_npz(f'{base_path}\\\\preprocessed\\\\X_test_uwarm_iwarm_transformed.npz', X_test_uwarm_iwarm_transformed)\n",
    "save_npz(f'{base_path}\\\\preprocessed\\\\X_test_uwarm_icold_transformed.npz', X_test_uwarm_icold_transformed)\n",
    "save_npz(f'{base_path}\\\\preprocessed\\\\X_test_ucold_iwarm_transformed.npz', X_test_ucold_iwarm_transformed)\n",
    "save_npz(f'{base_path}\\\\preprocessed\\\\X_test_ucold_icold_transformed.npz', X_test_ucold_icold_transformed)\n",
    "# Save target values to csv\n",
    "y_train.to_csv(f'{base_path}\\\\preprocessed\\\\y_train.csv', index=False)\n",
    "y_val.to_csv(f'{base_path}\\\\preprocessed\\\\y_val.csv', index=False)\n",
    "y_test_uwarm_iwarm.to_csv(f'{base_path}\\\\preprocessed\\\\y_test_uwarm_iwarm.csv', index=False)\n",
    "y_test_uwarm_icold.to_csv(f'{base_path}\\\\preprocessed\\\\y_test_uwarm_icold.csv', index=False)\n",
    "y_test_ucold_iwarm.to_csv(f'{base_path}\\\\preprocessed\\\\y_test_ucold_iwarm.csv', index=False)\n",
    "y_test_ucold_icold.to_csv(f'{base_path}\\\\preprocessed\\\\y_test_ucold_icold.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6208a61a",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c57e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transformed data from npz\n",
    "X_train_transformed = load_npz(f'{base_path}\\\\preprocessed\\\\X_train_transformed.npz')\n",
    "X_val_transformed = load_npz(f'{base_path}\\\\preprocessed\\\\X_val_transformed.npz')\n",
    "X_test_uwarm_iwarm_transformed = load_npz(f'{base_path}\\\\preprocessed\\\\X_test_uwarm_iwarm_transformed.npz')\n",
    "X_test_uwarm_icold_transformed = load_npz(f'{base_path}\\\\preprocessed\\\\X_test_uwarm_icold_transformed.npz')\n",
    "X_test_ucold_iwarm_transformed = load_npz(f'{base_path}\\\\preprocessed\\\\X_test_ucold_iwarm_transformed.npz')\n",
    "X_test_ucold_icold_transformed = load_npz(f'{base_path}\\\\preprocessed\\\\X_test_ucold_icold_transformed.npz')\n",
    "\n",
    "# Load target variables\n",
    "y_train = pd.read_csv(f'{base_path}\\\\preprocessed\\\\y_train.csv')\n",
    "y_val = pd.read_csv(f'{base_path}\\\\preprocessed\\\\y_val.csv')\n",
    "y_test_uwarm_iwarm = pd.read_csv(f'{base_path}\\\\preprocessed\\\\y_test_uwarm_iwarm.csv')\n",
    "y_test_uwarm_icold = pd.read_csv(f'{base_path}\\\\preprocessed\\\\y_test_uwarm_icold.csv')\n",
    "y_test_ucold_iwarm = pd.read_csv(f'{base_path}\\\\preprocessed\\\\y_test_ucold_iwarm.csv')\n",
    "y_test_ucold_icold = pd.read_csv(f'{base_path}\\\\preprocessed\\\\y_test_ucold_icold.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfea51f",
   "metadata": {},
   "source": [
    "## LightGBM model run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad505ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a LightGBM model\n",
    "lgb_model = lgb.LGBMRegressor(random_state=42)\n",
    "lgb_model.fit(X_train_transformed, y_train, feature_name=list(feature_names))\n",
    "\n",
    "y_pred_uwarm_iwarm = lgb_model.predict(X_test_uwarm_iwarm_transformed)\n",
    "y_pred_uwarm_icold = lgb_model.predict(X_test_uwarm_icold_transformed)\n",
    "y_pred_ucold_iwarm = lgb_model.predict(X_test_ucold_iwarm_transformed)\n",
    "y_pred_ucold_icold = lgb_model.predict(X_test_ucold_icold_transformed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d57878",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the predictions as RatingID, PredictedRating\n",
    "\n",
    "# Warm user warm item\n",
    "result_uwarm_iwarm = pd.DataFrame({\n",
    "    'RatingID': test_uwarm_iwarm['RatingID'],\n",
    "    'Rating': y_pred_uwarm_iwarm\n",
    "})\n",
    "result_uwarm_iwarm.to_csv(\n",
    "    f'{base_path}\\\\lightgbm\\\\lightgbm_warm_user_warm_item.csv', \n",
    "    index=False, \n",
    "    header=['RatingID', 'Rating']\n",
    ")\n",
    "# Warm user cold item\n",
    "result_uwarm_icold = pd.DataFrame({\n",
    "    'RatingID': test_uwarm_icold['RatingID'],\n",
    "    'Rating': y_pred_uwarm_icold\n",
    "})\n",
    "result_uwarm_icold.to_csv(\n",
    "    f'{base_path}\\\\lightgbm\\\\lightgbm_warm_user_cold_item.csv', \n",
    "    index=False, \n",
    "    header=['RatingID', 'Rating']\n",
    ")\n",
    "# Cold user warm item\n",
    "result_ucold_iwarm = pd.DataFrame({\n",
    "    'RatingID': test_ucold_iwarm['RatingID'],\n",
    "    'Rating': y_pred_ucold_iwarm\n",
    "})\n",
    "result_ucold_iwarm.to_csv(\n",
    "    f'{base_path}\\\\lightgbm\\\\lightgbm_cold_user_warm_item.csv', \n",
    "    index=False, \n",
    "    header=['RatingID', 'Rating']\n",
    ")\n",
    "# Cold user cold item\n",
    "result_ucold_icold = pd.DataFrame({\n",
    "    'RatingID': test_ucold_icold['RatingID'],\n",
    "    'Rating': y_pred_ucold_icold\n",
    "})\n",
    "result_ucold_icold.to_csv(\n",
    "    f'{base_path}\\\\lightgbm\\\\lightgbm_cold_user_cold_item.csv', \n",
    "    index=False, \n",
    "    header=['RatingID', 'Rating']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781c6b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "\n",
    "# Calculate MSE for each test set\n",
    "mse_uwarm_iwarm = mean_squared_error(y_test_uwarm_iwarm, y_pred_uwarm_iwarm)\n",
    "mse_uwarm_icold = mean_squared_error(y_test_uwarm_icold, y_pred_uwarm_icold)\n",
    "mse_ucold_iwarm = mean_squared_error(y_test_ucold_iwarm, y_pred_ucold_iwarm)\n",
    "mse_ucold_icold = mean_squared_error(y_test_ucold_icold, y_pred_ucold_icold)\n",
    "\n",
    "# Calculate RMSE for each test set\n",
    "rmse_uwarm_iwarm = root_mean_squared_error(y_test_uwarm_iwarm, y_pred_uwarm_iwarm)\n",
    "rmse_uwarm_icold = root_mean_squared_error(y_test_uwarm_icold, y_pred_uwarm_icold)\n",
    "rmse_ucold_iwarm = root_mean_squared_error(y_test_ucold_iwarm, y_pred_ucold_iwarm)\n",
    "rmse_ucold_icold = root_mean_squared_error(y_test_ucold_icold, y_pred_ucold_icold)\n",
    "\n",
    "# Calculate MAE for each test set\n",
    "mae_uwarm_iwarm = mean_absolute_error(y_test_uwarm_iwarm, y_pred_uwarm_iwarm)\n",
    "mae_uwarm_icold = mean_absolute_error(y_test_uwarm_icold, y_pred_uwarm_icold)\n",
    "mae_ucold_iwarm = mean_absolute_error(y_test_ucold_iwarm, y_pred_ucold_iwarm)\n",
    "mae_ucold_icold = mean_absolute_error(y_test_ucold_icold, y_pred_ucold_icold)\n",
    "\n",
    "# Print the results\n",
    "print(f'MSE for warm user warm item: {mse_uwarm_iwarm:.4f}')\n",
    "print(f'RMSE for warm user warm item: {rmse_uwarm_iwarm:.4f}')\n",
    "print(f'MAE for warm user warm item: {mae_uwarm_iwarm:.4f}')\n",
    "print('-' * 50)\n",
    "print(f'MSE for warm user cold item: {mse_uwarm_icold:.4f}')\n",
    "print(f'RMSE for warm user cold item: {rmse_uwarm_icold:.4f}')\n",
    "print(f'MAE for warm user cold item: {mae_uwarm_icold:.4f}')\n",
    "print('-' * 50)\n",
    "print(f'MSE for cold user warm item: {mse_ucold_iwarm:.4f}')\n",
    "print(f'RMSE for cold user warm item: {rmse_ucold_iwarm:.4f}')\n",
    "print(f'MAE for cold user warm item: {mae_ucold_iwarm:.4f}')\n",
    "print('-' * 50)\n",
    "print(f'MSE for cold user cold item: {mse_ucold_icold:.4f}')\n",
    "print(f'RMSE for cold user cold item: {rmse_ucold_icold:.4f}')\n",
    "print(f'MAE for cold user cold item: {mae_ucold_icold:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8203f0",
   "metadata": {},
   "source": [
    "## XGBoost model run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4c8562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost with DMatrix\n",
    "dtrain = xgb.DMatrix(X_train_transformed, label=y_train, feature_names=list(feature_names))\n",
    "xgb_model = xgb.train(\n",
    "    params={\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "        'seed': 42\n",
    "    },\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=100\n",
    ")\n",
    "\n",
    "d_test_uwarm_iwarm = xgb.DMatrix(X_test_uwarm_iwarm_transformed, feature_names=list(feature_names))\n",
    "d_test_uwarm_icold = xgb.DMatrix(X_test_uwarm_icold_transformed, feature_names=list(feature_names))\n",
    "d_test_ucold_iwarm = xgb.DMatrix(X_test_ucold_iwarm_transformed, feature_names=list(feature_names))\n",
    "d_test_ucold_icold = xgb.DMatrix(X_test_ucold_icold_transformed, feature_names=list(feature_names))\n",
    "\n",
    "# Predict using the trained model\n",
    "y_pred_uwarm_iwarm = xgb_model.predict(d_test_uwarm_iwarm)\n",
    "y_pred_uwarm_icold = xgb_model.predict(d_test_uwarm_icold)\n",
    "y_pred_ucold_iwarm = xgb_model.predict(d_test_ucold_iwarm)\n",
    "y_pred_ucold_icold = xgb_model.predict(d_test_ucold_icold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400171b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the predictions as RatingID, PredictedRating\n",
    "# Warm user warm item\n",
    "result_uwarm_iwarm = pd.DataFrame({\n",
    "    'RatingID': test_uwarm_iwarm['RatingID'],\n",
    "    'Rating': y_pred_uwarm_iwarm\n",
    "})\n",
    "result_uwarm_iwarm.to_csv(\n",
    "    f'{base_path}\\\\xgboost\\\\xgboost_warm_user_warm_item.csv', \n",
    "    index=False, \n",
    "    header=['RatingID', 'Rating']\n",
    ")\n",
    "# Warm user cold item\n",
    "result_uwarm_icold = pd.DataFrame({\n",
    "    'RatingID': test_uwarm_icold['RatingID'],\n",
    "    'Rating': y_pred_uwarm_icold\n",
    "})\n",
    "result_uwarm_icold.to_csv(\n",
    "    f'{base_path}\\\\xgboost\\\\xgboost_warm_user_cold_item.csv', \n",
    "    index=False, \n",
    "    header=['RatingID', 'Rating']\n",
    ")\n",
    "# Cold user warm item\n",
    "result_ucold_iwarm = pd.DataFrame({\n",
    "    'RatingID': test_ucold_iwarm['RatingID'],\n",
    "    'Rating': y_pred_ucold_iwarm\n",
    "})\n",
    "result_ucold_iwarm.to_csv(\n",
    "    f'{base_path}\\\\xgboost\\\\xgboost_cold_user_warm_item.csv', \n",
    "    index=False, \n",
    "    header=['RatingID', 'Rating']\n",
    ")\n",
    "# Cold user cold item\n",
    "result_ucold_icold = pd.DataFrame({\n",
    "    'RatingID': test_ucold_icold['RatingID'],\n",
    "    'Rating': y_pred_ucold_icold\n",
    "})\n",
    "result_ucold_icold.to_csv(\n",
    "    f'{base_path}\\\\xgboost\\\\xgboost_cold_user_cold_item.csv', \n",
    "    index=False, \n",
    "    header=['RatingID', 'Rating']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af764b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "# Calculate MSE for each test set\n",
    "mse_uwarm_iwarm = mean_squared_error(y_test_uwarm_iwarm, y_pred_uwarm_iwarm)\n",
    "mse_uwarm_icold = mean_squared_error(y_test_uwarm_icold, y_pred_uwarm_icold)\n",
    "mse_ucold_iwarm = mean_squared_error(y_test_ucold_iwarm, y_pred_ucold_iwarm)\n",
    "mse_ucold_icold = mean_squared_error(y_test_ucold_icold, y_pred_ucold_icold)\n",
    "# Calculate RMSE for each test set\n",
    "rmse_uwarm_iwarm = root_mean_squared_error(y_test_uwarm_iwarm, y_pred_uwarm_iwarm)\n",
    "rmse_uwarm_icold = root_mean_squared_error(y_test_uwarm_icold, y_pred_uwarm_icold)\n",
    "rmse_ucold_iwarm = root_mean_squared_error(y_test_ucold_iwarm, y_pred_ucold_iwarm)\n",
    "rmse_ucold_icold = root_mean_squared_error(y_test_ucold_icold, y_pred_ucold_icold)\n",
    "# Calculate MAE for each test set\n",
    "mae_uwarm_iwarm = mean_absolute_error(y_test_uwarm_iwarm, y_pred_uwarm_iwarm)\n",
    "mae_uwarm_icold = mean_absolute_error(y_test_uwarm_icold, y_pred_uwarm_icold)\n",
    "mae_ucold_iwarm = mean_absolute_error(y_test_ucold_iwarm, y_pred_ucold_iwarm)\n",
    "mae_ucold_icold = mean_absolute_error(y_test_ucold_icold, y_pred_ucold_icold)\n",
    "# Print the results\n",
    "print(f'MSE for warm user warm item: {mse_uwarm_iwarm:.4f}')\n",
    "print(f'RMSE for warm user warm item: {rmse_uwarm_iwarm:.4f}')\n",
    "print(f'MAE for warm user warm item: {mae_uwarm_iwarm:.4f}')\n",
    "print('-' * 50)\n",
    "print(f'MSE for warm user cold item: {mse_uwarm_icold:.4f}')\n",
    "print(f'RMSE for warm user cold item: {rmse_uwarm_icold:.4f}')\n",
    "print(f'MAE for warm user cold item: {mae_uwarm_icold:.4f}')\n",
    "print('-' * 50)\n",
    "print(f'MSE for cold user warm item: {mse_ucold_iwarm:.4f}')\n",
    "print(f'RMSE for cold user warm item: {rmse_ucold_iwarm:.4f}')\n",
    "print(f'MAE for cold user warm item: {mae_ucold_iwarm:.4f}')\n",
    "print('-' * 50)\n",
    "print(f'MSE for cold user cold item: {mse_ucold_icold:.4f}')\n",
    "print(f'RMSE for cold user cold item: {rmse_ucold_icold:.4f}')\n",
    "print(f'MAE for cold user cold item: {mae_ucold_icold:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b060542f",
   "metadata": {},
   "source": [
    "# Evaluate top-k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dfc795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "results_uwarm_iwarm = pd.read_csv(\n",
    "    f'{base_path}\\\\xgboost\\\\xgboost_warm_user_warm_item.csv', \n",
    "    usecols=['RatingID', 'Rating']\n",
    ")\n",
    "results_uwarm_icold = pd.read_csv(\n",
    "    f'{base_path}\\\\xgboost\\\\xgboost_warm_user_cold_item.csv', \n",
    "    usecols=['RatingID', 'Rating']\n",
    ")\n",
    "results_ucold_iwarm = pd.read_csv(\n",
    "    f'{base_path}\\\\xgboost\\\\xgboost_cold_user_warm_item.csv', \n",
    "    usecols=['RatingID', 'Rating']\n",
    ")\n",
    "results_ucold_icold = pd.read_csv(\n",
    "    f'{base_path}\\\\xgboost\\\\xgboost_cold_user_cold_item.csv', \n",
    "    usecols=['RatingID', 'Rating']\n",
    ")\n",
    "\n",
    "# Load the test set\n",
    "test_uwarm_iwarm = pd.read_csv(\n",
    "    f'{base_path}\\\\testset_warm_user_warm_item.csv', \n",
    "    usecols=['RatingID', 'UserID', 'WineID', 'Rating']\n",
    ")\n",
    "test_uwarm_icold = pd.read_csv(\n",
    "    f'{base_path}\\\\testset_warm_user_cold_item.csv', \n",
    "    usecols=['RatingID', 'UserID', 'WineID', 'Rating']\n",
    ")\n",
    "test_ucold_iwarm = pd.read_csv(\n",
    "    f'{base_path}\\\\testset_cold_user_warm_item.csv', \n",
    "    usecols=['RatingID', 'UserID', 'WineID', 'Rating']\n",
    ")\n",
    "test_ucold_icold = pd.read_csv(\n",
    "    f'{base_path}\\\\testset_cold_user_cold_item.csv', \n",
    "    usecols=['RatingID', 'UserID', 'WineID', 'Rating']\n",
    ")\n",
    "# Merge the results with the test set\n",
    "results_uwarm_iwarm = results_uwarm_iwarm.merge(test_uwarm_iwarm, on='RatingID', how='left')\n",
    "results_uwarm_icold = results_uwarm_icold.merge(test_uwarm_icold, on='RatingID', how='left')\n",
    "results_ucold_iwarm = results_ucold_iwarm.merge(test_ucold_iwarm, on='RatingID', how='left')\n",
    "results_ucold_icold = results_ucold_icold.merge(test_ucold_icold, on='RatingID', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c9e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Rank and Rank_pred columns\n",
    "\n",
    "# Warm user, warm item\n",
    "results_uwarm_iwarm[\"Rank\"] = results_uwarm_iwarm.groupby(\"UserID\")[\"Rating_y\"].rank(method=\"first\", ascending=False)\n",
    "results_uwarm_iwarm[\"Rank_pred\"] = results_uwarm_iwarm.groupby(\"UserID\")[\"Rating_x\"].rank(method=\"first\", ascending=False)\n",
    "# Warm user, cold item\n",
    "results_uwarm_icold[\"Rank\"] = results_uwarm_icold.groupby(\"UserID\")[\"Rating_y\"].rank(method=\"first\", ascending=False)\n",
    "results_uwarm_icold[\"Rank_pred\"] = results_uwarm_icold.groupby(\"UserID\")[\"Rating_x\"].rank(method=\"first\", ascending=False)\n",
    "# Cold user, warm item\n",
    "results_ucold_iwarm[\"Rank\"] = results_ucold_iwarm.groupby(\"UserID\")[\"Rating_y\"].rank(method=\"first\", ascending=False)\n",
    "results_ucold_iwarm[\"Rank_pred\"] = results_ucold_iwarm.groupby(\"UserID\")[\"Rating_x\"].rank(method=\"first\", ascending=False)\n",
    "# Cold user, cold item\n",
    "results_ucold_icold[\"Rank\"] = results_ucold_icold.groupby(\"UserID\")[\"Rating_y\"].rank(method=\"first\", ascending=False)\n",
    "results_ucold_icold[\"Rank_pred\"] = results_ucold_icold.groupby(\"UserID\")[\"Rating_x\"].rank(method=\"first\", ascending=False)\n",
    "\n",
    "# Calculate Relevance\n",
    "results_uwarm_iwarm[\"Relevance\"] = results_uwarm_iwarm[\"Rating_y\"].apply(lambda x: 1 if x >= 3.5 else 0)\n",
    "results_uwarm_icold[\"Relevance\"] = results_uwarm_icold[\"Rating_y\"].apply(lambda x: 1 if x >= 3.5 else 0)\n",
    "results_ucold_iwarm[\"Relevance\"] = results_ucold_iwarm[\"Rating_y\"].apply(lambda x: 1 if x >= 3.5 else 0)\n",
    "results_ucold_icold[\"Relevance\"] = results_ucold_icold[\"Rating_y\"].apply(lambda x: 1 if x >= 3.5 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56e331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_topk_fast(df, k=10):\n",
    "    # Pre-sort so top-k is at the top per user\n",
    "    df = df.sort_values(['UserID', 'Rank_pred'], ascending=[True, True])\n",
    "\n",
    "    # Assign group index per row (unique integer per user)\n",
    "    user_index, user_pos = np.unique(df['UserID'], return_inverse=True)\n",
    "\n",
    "    # Count items per user\n",
    "    user_counts = np.bincount(user_pos)\n",
    "    user_offsets = np.zeros(len(df), dtype=int)\n",
    "    np.add.at(user_offsets, np.cumsum(user_counts)[:-1], 1)\n",
    "    user_offsets = np.cumsum(user_offsets)\n",
    "\n",
    "    # Mask to keep only top-k per user\n",
    "    df['row_number'] = df.groupby('UserID').cumcount()\n",
    "    topk_df = df[df['row_number'] < k].copy()\n",
    "\n",
    "    # Precision@k\n",
    "    precision = topk_df['Relevance'].groupby(topk_df['UserID']).mean().mean()\n",
    "\n",
    "    # Recall@k\n",
    "    relevant_per_user = df.groupby('UserID')['Relevance'].sum()\n",
    "    hits_per_user = topk_df.groupby('UserID')['Relevance'].sum()\n",
    "    recall = (hits_per_user / relevant_per_user).fillna(0).mean()\n",
    "\n",
    "    # HitRate@k\n",
    "    hits = (hits_per_user > 0).astype(int)\n",
    "    hit_rate = hits.mean()\n",
    "\n",
    "    # MAP@k\n",
    "    def map_at_k_per_user(x):\n",
    "        rels = x['Relevance'].values\n",
    "        precisions = [(rels[:i + 1].sum() / (i + 1)) for i in range(len(rels)) if rels[i]]\n",
    "        return np.mean(precisions) if precisions else 0\n",
    "    mapk = topk_df.groupby('UserID').apply(map_at_k_per_user).mean()\n",
    "\n",
    "    # nDCG@k\n",
    "    def dcg(rels):\n",
    "        return np.sum(rels / np.log2(np.arange(2, len(rels) + 2)))\n",
    "    def ndcg_per_user(x):\n",
    "        dcg_val = dcg(x['Relevance'].values)\n",
    "        ideal = x.sort_values('Relevance', ascending=False).head(k)\n",
    "        idcg_val = dcg(ideal['Relevance'].values)\n",
    "        return dcg_val / idcg_val if idcg_val > 0 else 0\n",
    "    ndcg = topk_df.groupby('UserID').apply(ndcg_per_user).mean()\n",
    "\n",
    "    return {\n",
    "        'Precision@k': precision,\n",
    "        'Recall@k': recall,\n",
    "        'HitRate@k': hit_rate,\n",
    "        'MAP@k': mapk,\n",
    "        'nDCG@k': ndcg\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4447408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation\n",
    "k = 10\n",
    "results = {}\n",
    "results['warm user, warm item'] = evaluate_topk_fast(results_uwarm_iwarm, k=k)\n",
    "results['warm user, cold item'] = evaluate_topk_fast(results_uwarm_icold, k=k)\n",
    "results['cold user, warm item'] = evaluate_topk_fast(results_ucold_iwarm, k=k)\n",
    "results['cold user, cold item'] = evaluate_topk_fast(results_ucold_icold, k=k)\n",
    "\n",
    "# Print evaluation results\n",
    "for case, metrics in results.items():\n",
    "    print(f\"Evaluation on {case} at top {k}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a941aa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# LGBM tuning\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"verbosity\": -1,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 512),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 16),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.6, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.6, 1.0),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 0.0, 10.0),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 0.0, 10.0),\n",
    "    }\n",
    "\n",
    "    lgb_train = lgb.Dataset(X_train_transformed, y_train)\n",
    "    lgb_valid = lgb.Dataset(X_val_transformed, y_val, reference=lgb_train)\n",
    "\n",
    "    model = lgb.train(params, lgb_train,\n",
    "                      valid_sets=[lgb_valid],\n",
    "                      callbacks=[lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(period=0)],\n",
    "                    )\n",
    "    preds = model.predict(X_val_transformed)\n",
    "    return -mean_squared_error(y_val, preds) \n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50, timeout=3600)  # 1 hour\n",
    "\n",
    "# Save the best model to pkl\n",
    "with open(f'{base_path}\\\\lightgbm\\\\lgbm_model.pkl', 'wb') as f:\n",
    "    pickle.dump(study, f)\n",
    "    \n",
    "best_model = lgb.LGBMRegressor(**study.best_params)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webmining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

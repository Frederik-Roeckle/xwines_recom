{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96787365",
   "metadata": {},
   "source": [
    "# Model-Based recommender system\n",
    "## Plan\n",
    "* Dataset of WineID,UserID,Rating\n",
    "* Train using MF(SVD)\n",
    "* Evaluate\n",
    "\n",
    "### Singular Value Decomposition (SVD) algorithm\n",
    "#### https://surprise.readthedocs.io/en/stable/matrix_factorization.html\n",
    "Is a Matrix Factorization algorithm (Probabalistic MF if biases are not used). Minimizes the regularized square error by straightforward Stohastic Gradient Descent.\n",
    "\n",
    "Pros:\n",
    "- Has high accuracy\n",
    "- Scales well on large data\n",
    "- Dimestionality reduction\n",
    "\n",
    "Cons:\n",
    "- Doesn't handle cold-start problem without additional modifications (like hybrid models, pre-training clustering together similar users and items)\n",
    "- Hard to interpret due to latent factors\n",
    "- SVD doesn't use any metadata\n",
    "\n",
    "Why use SVD?\n",
    "1. Large dataset (trainset ~16 mill rows)\n",
    "2. No user metadata\n",
    "3. Handles only warm-warm start, is not designed to handle any of cold-start scenarions.\n",
    "However the RMSE scores look good here since in cold start cases the SVD model from surprise just take the global mean for unseen items/users.\n",
    "Attempt to handle cold-start with Hybrid model (CF + Content-based)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23a81cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, root_mean_squared_error\n",
    "from surprise import SVD, Dataset, Reader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09271dce",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\..\\\\Evaluation\\\\trainset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m base_path = \u001b[33m'\u001b[39m\u001b[33m..\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33m..\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mEvaluation\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      4\u001b[39m all_wines = pd.read_csv(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mXWines_Full_21M_ratings.csv\u001b[39m\u001b[33m'\u001b[39m, usecols=[\u001b[33m'\u001b[39m\u001b[33mRatingID\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mUserID\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mWineID\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mRating\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m train = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbase_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mtrainset.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mUserID\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mWineID\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mRating\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m test_uwarm_iwarm = pd.read_csv(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mtestset_warm_user_warm_item.csv\u001b[39m\u001b[33m'\u001b[39m, usecols=[\u001b[33m'\u001b[39m\u001b[33mRatingID\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mUserID\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mWineID\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mRating\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      7\u001b[39m test_uwarm_icold = pd.read_csv(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mtestset_warm_user_cold_item.csv\u001b[39m\u001b[33m'\u001b[39m, usecols=[\u001b[33m'\u001b[39m\u001b[33mRatingID\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mUserID\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mWineID\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mRating\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Denis\\envs\\webmining\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Denis\\envs\\webmining\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Denis\\envs\\webmining\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Denis\\envs\\webmining\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Denis\\envs\\webmining\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '..\\\\..\\\\Evaluation\\\\trainset.csv'"
     ]
    }
   ],
   "source": [
    "# Data loading\n",
    "base_path = '..\\\\..\\\\Evaluation'\n",
    "\n",
    "train = pd.read_csv(f'{base_path}\\\\trainset.csv', usecols=['UserID', 'WineID', 'Rating'])\n",
    "test_uwarm_iwarm = pd.read_csv(f'{base_path}\\\\testset_warm_user_warm_item.csv', usecols=['RatingID', 'UserID', 'WineID', 'Rating'])\n",
    "test_uwarm_icold = pd.read_csv(f'{base_path}\\\\testset_warm_user_cold_item.csv', usecols=['RatingID', 'UserID', 'WineID', 'Rating'])\n",
    "test_ucold_iwarm = pd.read_csv(f'{base_path}\\\\testset_cold_user_warm_item.csv', usecols=['RatingID', 'UserID', 'WineID', 'Rating'])\n",
    "test_ucold_icold = pd.read_csv(f'{base_path}\\\\testset_cold_user_cold_item.csv', usecols=['RatingID', 'UserID', 'WineID', 'Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c551542c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (16917894, 3)\n",
      "Test set shape (warm user, warm item): (2036778, 4)\n",
      "Test set shape (warm user, cold item): (35456, 4)\n",
      "Test set shape (cold user, warm item): (506800, 4)\n",
      "Test set shape (cold user, cold item): (16504, 4)\n"
     ]
    }
   ],
   "source": [
    "print('Train set shape:', train.shape)\n",
    "print('Test set shape (warm user, warm item):', test_uwarm_iwarm.shape)\n",
    "print('Test set shape (warm user, cold item):', test_uwarm_icold.shape)\n",
    "print('Test set shape (cold user, warm item):', test_ucold_iwarm.shape)\n",
    "print('Test set shape (cold user, cold item):', test_ucold_icold.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdded934",
   "metadata": {},
   "source": [
    "## SVD using Surprise library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec1e8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use only raw data since Surprise handles the encoding internally\n",
    "\n",
    "# For train: convert to Surprise format\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "train_data = Dataset.load_from_df(train[['UserID', 'WineID', 'Rating']], reader)\n",
    "train_surprise = train_data.build_full_trainset()\n",
    "\n",
    "# For test: convert to Surprise format\n",
    "test_uwarm_iwarm_surprise = list(test_uwarm_iwarm[['UserID', 'WineID', 'Rating']].itertuples(index=False, name=None))\n",
    "test_uwarm_icold_surprise = list(test_uwarm_icold[['UserID', 'WineID', 'Rating']].itertuples(index=False, name=None))\n",
    "test_ucold_iwarm_surprise = list(test_ucold_iwarm[['UserID', 'WineID', 'Rating']].itertuples(index=False, name=None))\n",
    "test_ucold_icold_surprise = list(test_ucold_icold[['UserID', 'WineID', 'Rating']].itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3186b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Results:\n",
      "MSE (warm user, warm item): 0.3198472927282139\n",
      "RMSE (warm user, warm item): 0.5655504334082098\n",
      "MAE (warm user, warm item): 0.412036745658953\n",
      "--------------------------------------------------\n",
      "MSE (warm user, cold item): 0.41533766974870867\n",
      "RMSE (warm user, cold item): 0.644466965599253\n",
      "MAE (warm user, cold item): 0.47336789039746074\n",
      "--------------------------------------------------\n",
      "MSE (cold user, warm item): 0.44334311057386555\n",
      "RMSE (cold user, warm item): 0.6658401539212437\n",
      "MAE (cold user, warm item): 0.49323154327054913\n",
      "--------------------------------------------------\n",
      "MSE (cold user, cold item): 0.5983717312186697\n",
      "RMSE (cold user, cold item): 0.7735449122182045\n",
      "MAE (cold user, cold item): 0.574148821209833\n"
     ]
    }
   ],
   "source": [
    "# Train SVD\n",
    "model = SVD()\n",
    "model.fit(train_surprise)\n",
    "\n",
    "# Predict ratings for test sets\n",
    "pred_uwarm_iwarm = model.test(test_uwarm_iwarm_surprise)\n",
    "pred_uwarm_icold = model.test(test_uwarm_icold_surprise)\n",
    "pred_ucold_iwarm = model.test(test_ucold_iwarm_surprise)\n",
    "pred_ucold_icold = model.test(test_ucold_icold_surprise)\n",
    "\n",
    "# Convert redicted ratings to list\n",
    "pred_uwarm_iwarm = [pred.est for pred in pred_uwarm_iwarm]\n",
    "pred_uwarm_icold = [pred.est for pred in pred_uwarm_icold]\n",
    "pred_ucold_iwarm = [pred.est for pred in pred_ucold_iwarm]\n",
    "pred_ucold_icold = [pred.est for pred in pred_ucold_icold]\n",
    "\n",
    "# Save predictions to dataframe \n",
    "test_uwarm_iwarm['Prediction'] = pred_uwarm_iwarm\n",
    "test_uwarm_icold['Prediction'] = pred_uwarm_icold\n",
    "test_ucold_iwarm['Prediction'] = pred_ucold_iwarm\n",
    "test_ucold_icold['Prediction'] = pred_ucold_icold\n",
    "\n",
    "# Write predictions to CSV [RatingID, Prediction]\n",
    "test_uwarm_iwarm.to_csv(f'{base_path}/svd/svd_warm_user_warm_item.csv', index=False, columns=['RatingID', 'Prediction'], header=['RatingID', 'Rating'])\n",
    "test_uwarm_icold.to_csv(f'{base_path}/svd/svd_warm_user_cold_item.csv', index=False, columns=['RatingID', 'Prediction'], header=['RatingID', 'Rating'])\n",
    "test_ucold_iwarm.to_csv(f'{base_path}/svd/svd_cold_user_warm_item.csv', index=False, columns=['RatingID', 'Prediction'], header=['RatingID', 'Rating'])\n",
    "test_ucold_icold.to_csv(f'{base_path}/svd/svd_cold_user_cold_item.csv', index=False, columns=['RatingID', 'Prediction'], header=['RatingID', 'Rating'])\n",
    "\n",
    "# Evaluate MSE\n",
    "mse_uwarm_iwarm = mean_squared_error(test_uwarm_iwarm['Rating'], pred_uwarm_iwarm)\n",
    "mse_uwarm_icold = mean_squared_error(test_uwarm_icold['Rating'], pred_uwarm_icold)\n",
    "mse_ucold_iwarm = mean_squared_error(test_ucold_iwarm['Rating'], pred_ucold_iwarm)\n",
    "mse_ucold_icold = mean_squared_error(test_ucold_icold['Rating'], pred_ucold_icold)\n",
    "\n",
    "# Evaluate RMSE\n",
    "rmse_uwarm_iwarm = root_mean_squared_error(test_uwarm_iwarm['Rating'], pred_uwarm_iwarm)\n",
    "rmse_uwarm_icold = root_mean_squared_error(test_uwarm_icold['Rating'], pred_uwarm_icold)\n",
    "rmse_ucold_iwarm = root_mean_squared_error(test_ucold_iwarm['Rating'], pred_ucold_iwarm)\n",
    "rmse_ucold_icold = root_mean_squared_error(test_ucold_icold['Rating'], pred_ucold_icold)\n",
    "\n",
    "\n",
    "# Evaluate MAE\n",
    "mae_uwarm_iwarm = mean_absolute_error(test_uwarm_iwarm['Rating'], pred_uwarm_iwarm)\n",
    "mae_uwarm_icold = mean_absolute_error(test_uwarm_icold['Rating'], pred_uwarm_icold)\n",
    "mae_ucold_iwarm = mean_absolute_error(test_ucold_iwarm['Rating'], pred_ucold_iwarm)\n",
    "mae_ucold_icold = mean_absolute_error(test_ucold_icold['Rating'], pred_ucold_icold)\n",
    "\n",
    "\n",
    "# Print results\n",
    "print('SVD Results:')\n",
    "print('MSE (warm user, warm item):', mse_uwarm_iwarm)\n",
    "print('RMSE (warm user, warm item):', rmse_uwarm_iwarm)\n",
    "print('MAE (warm user, warm item):', mae_uwarm_iwarm)\n",
    "print('-' * 50)\n",
    "print('MSE (warm user, cold item):', mse_uwarm_icold)\n",
    "print('RMSE (warm user, cold item):', rmse_uwarm_icold)\n",
    "print('MAE (warm user, cold item):', mae_uwarm_icold)\n",
    "print('-' * 50)\n",
    "print('MSE (cold user, warm item):', mse_ucold_iwarm)\n",
    "print('RMSE (cold user, warm item):', rmse_ucold_iwarm)\n",
    "print('MAE (cold user, warm item):', mae_ucold_iwarm)\n",
    "print('-' * 50)\n",
    "print('MSE (cold user, cold item):', mse_ucold_icold)\n",
    "print('RMSE (cold user, cold item):', rmse_ucold_icold)\n",
    "print('MAE (cold user, cold item):', mae_ucold_icold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db23fe4d",
   "metadata": {},
   "source": [
    "# Evaluate top-k, since MSE/RMSE/MAE are not really descriptive in cold-start cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d02c5776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions\n",
    "pred_uwarm_iwarm = pd.read_csv(f'{base_path}\\\\svd\\\\svd_warm_user_warm_item.csv')\n",
    "pred_uwarm_icold = pd.read_csv(f'{base_path}\\\\svd\\\\svd_warm_user_cold_item.csv')\n",
    "pred_ucold_iwarm = pd.read_csv(f'{base_path}\\\\svd\\\\svd_cold_user_warm_item.csv')\n",
    "pred_ucold_icold = pd.read_csv(f'{base_path}\\\\svd\\\\svd_cold_user_cold_item.csv')\n",
    "# Merge predictions with test sets\n",
    "pred_uwarm_iwarm = pd.merge(test_uwarm_iwarm, pred_uwarm_iwarm, on='RatingID', how='inner', suffixes=('', '_pred'))\n",
    "pred_uwarm_icold = pd.merge(test_uwarm_icold, pred_uwarm_icold, on='RatingID', how='inner', suffixes=('', '_pred'))\n",
    "pred_ucold_iwarm = pd.merge(test_ucold_iwarm, pred_ucold_iwarm, on='RatingID', how='inner', suffixes=('', '_pred'))\n",
    "pred_ucold_icold = pd.merge(test_ucold_icold, pred_ucold_icold, on='RatingID', how='inner', suffixes=('', '_pred'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08153634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Rank and Rank_pred columns\n",
    "\n",
    "# Warm user, warm item\n",
    "pred_uwarm_iwarm[\"Rank\"] = pred_uwarm_iwarm.groupby(\"UserID\")[\"Rating\"].rank(method=\"first\", ascending=False)\n",
    "pred_uwarm_iwarm[\"Rank_pred\"] = pred_uwarm_iwarm.groupby(\"UserID\")[\"Rating_pred\"].rank(method=\"first\", ascending=False)\n",
    "# Warm user, cold item\n",
    "pred_uwarm_icold[\"Rank\"] = pred_uwarm_icold.groupby(\"UserID\")[\"Rating\"].rank(method=\"first\", ascending=False)\n",
    "pred_uwarm_icold[\"Rank_pred\"] = pred_uwarm_icold.groupby(\"UserID\")[\"Rating_pred\"].rank(method=\"first\", ascending=False)\n",
    "# Cold user, warm item\n",
    "pred_ucold_iwarm[\"Rank\"] = pred_ucold_iwarm.groupby(\"UserID\")[\"Rating\"].rank(method=\"first\", ascending=False)\n",
    "pred_ucold_iwarm[\"Rank_pred\"] = pred_ucold_iwarm.groupby(\"UserID\")[\"Rating_pred\"].rank(method=\"first\", ascending=False)\n",
    "# Cold user, cold item\n",
    "pred_ucold_icold[\"Rank\"] = pred_ucold_icold.groupby(\"UserID\")[\"Rating\"].rank(method=\"first\", ascending=False)\n",
    "pred_ucold_icold[\"Rank_pred\"] = pred_ucold_icold.groupby(\"UserID\")[\"Rating_pred\"].rank(method=\"first\", ascending=False)\n",
    "\n",
    "# Calculate Relevance\n",
    "pred_uwarm_iwarm[\"Relevance\"] = pred_uwarm_iwarm[\"Rating\"].apply(lambda x: 1 if x >= 3.5 else 0)\n",
    "pred_uwarm_icold[\"Relevance\"] = pred_uwarm_icold[\"Rating\"].apply(lambda x: 1 if x >= 3.5 else 0)\n",
    "pred_ucold_iwarm[\"Relevance\"] = pred_ucold_iwarm[\"Rating\"].apply(lambda x: 1 if x >= 3.5 else 0)\n",
    "pred_ucold_icold[\"Relevance\"] = pred_ucold_icold[\"Rating\"].apply(lambda x: 1 if x >= 3.5 else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50e412a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_topk_fast(df, k=10):\n",
    "    # Pre-sort so top-k is at the top per user\n",
    "    df = df.sort_values(['UserID', 'Rank_pred'], ascending=[True, True])\n",
    "\n",
    "    # Assign group index per row (unique integer per user)\n",
    "    user_index, user_pos = np.unique(df['UserID'], return_inverse=True)\n",
    "\n",
    "    # Count items per user\n",
    "    user_counts = np.bincount(user_pos)\n",
    "    user_offsets = np.zeros(len(df), dtype=int)\n",
    "    np.add.at(user_offsets, np.cumsum(user_counts)[:-1], 1)\n",
    "    user_offsets = np.cumsum(user_offsets)\n",
    "\n",
    "    # Mask to keep only top-k per user\n",
    "    df['row_number'] = df.groupby('UserID').cumcount()\n",
    "    topk_df = df[df['row_number'] < k].copy()\n",
    "\n",
    "    # Precision@k\n",
    "    precision = topk_df['Relevance'].groupby(topk_df['UserID']).mean().mean()\n",
    "\n",
    "    # Recall@k\n",
    "    relevant_per_user = df.groupby('UserID')['Relevance'].sum()\n",
    "    hits_per_user = topk_df.groupby('UserID')['Relevance'].sum()\n",
    "    recall = (hits_per_user / relevant_per_user).fillna(0).mean()\n",
    "\n",
    "    # HitRate@k\n",
    "    hits = (hits_per_user > 0).astype(int)\n",
    "    hit_rate = hits.mean()\n",
    "\n",
    "    # MAP@k\n",
    "    def map_at_k_per_user(x):\n",
    "        rels = x['Relevance'].values\n",
    "        precisions = [(rels[:i + 1].sum() / (i + 1)) for i in range(len(rels)) if rels[i]]\n",
    "        return np.mean(precisions) if precisions else 0\n",
    "    mapk = topk_df.groupby('UserID').apply(map_at_k_per_user, include_groups=False).mean()\n",
    "\n",
    "    # nDCG@k\n",
    "    def dcg(rels):\n",
    "        return np.sum(rels / np.log2(np.arange(2, len(rels) + 2)))\n",
    "    def ndcg_per_user(x):\n",
    "        dcg_val = dcg(x['Relevance'].values)\n",
    "        ideal = x.sort_values('Relevance', ascending=False).head(k)\n",
    "        idcg_val = dcg(ideal['Relevance'].values)\n",
    "        return dcg_val / idcg_val if idcg_val > 0 else 0\n",
    "    ndcg = topk_df.groupby('UserID').apply(ndcg_per_user, include_groups=False).mean()\n",
    "\n",
    "    return {\n",
    "        f'Precision@{k}': precision,\n",
    "        f'Recall@{k}': recall,\n",
    "        f'HitRate@{k}': hit_rate,\n",
    "        f'MAP@{k}': mapk,\n",
    "        f'nDCG@{k}': ndcg\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41b2a337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on warm user, warm item at top 10:\n",
      "Precision@10: 0.8819\n",
      "Recall@10: 0.9238\n",
      "HitRate@10: 0.9526\n",
      "MAP@10: 0.9261\n",
      "nDCG@10: 0.9362\n",
      "--------------------------------------------------\n",
      "Evaluation on warm user, cold item at top 10:\n",
      "Precision@10: 0.8389\n",
      "Recall@10: 0.8605\n",
      "HitRate@10: 0.8605\n",
      "MAP@10: 0.8479\n",
      "nDCG@10: 0.8515\n",
      "--------------------------------------------------\n",
      "Evaluation on cold user, warm item at top 10:\n",
      "Precision@10: 0.8192\n",
      "Recall@10: 0.9233\n",
      "HitRate@10: 0.9929\n",
      "MAP@10: 0.9164\n",
      "nDCG@10: 0.9489\n",
      "--------------------------------------------------\n",
      "Evaluation on cold user, cold item at top 10:\n",
      "Precision@10: 0.7089\n",
      "Recall@10: 0.7210\n",
      "HitRate@10: 0.7210\n",
      "MAP@10: 0.7139\n",
      "nDCG@10: 0.7159\n",
      "--------------------------------------------------\n",
      "Evaluation on warm user, warm item at top 20:\n",
      "Precision@20: 0.8795\n",
      "Recall@20: 0.9437\n",
      "HitRate@20: 0.9526\n",
      "MAP@20: 0.9253\n",
      "nDCG@20: 0.9360\n",
      "--------------------------------------------------\n",
      "Evaluation on warm user, cold item at top 20:\n",
      "Precision@20: 0.8389\n",
      "Recall@20: 0.8605\n",
      "HitRate@20: 0.8605\n",
      "MAP@20: 0.8479\n",
      "nDCG@20: 0.8515\n",
      "--------------------------------------------------\n",
      "Evaluation on cold user, warm item at top 20:\n",
      "Precision@20: 0.8112\n",
      "Recall@20: 0.9761\n",
      "HitRate@20: 0.9930\n",
      "MAP@20: 0.9134\n",
      "nDCG@20: 0.9483\n",
      "--------------------------------------------------\n",
      "Evaluation on cold user, cold item at top 20:\n",
      "Precision@20: 0.7089\n",
      "Recall@20: 0.7210\n",
      "HitRate@20: 0.7210\n",
      "MAP@20: 0.7139\n",
      "nDCG@20: 0.7159\n",
      "--------------------------------------------------\n",
      "Evaluation on warm user, warm item at top 50:\n",
      "Precision@50: 0.8784\n",
      "Recall@50: 0.9514\n",
      "HitRate@50: 0.9526\n",
      "MAP@50: 0.9250\n",
      "nDCG@50: 0.9360\n",
      "--------------------------------------------------\n",
      "Evaluation on warm user, cold item at top 50:\n",
      "Precision@50: 0.8389\n",
      "Recall@50: 0.8605\n",
      "HitRate@50: 0.8605\n",
      "MAP@50: 0.8479\n",
      "nDCG@50: 0.8515\n",
      "--------------------------------------------------\n",
      "Evaluation on cold user, warm item at top 50:\n",
      "Precision@50: 0.8088\n",
      "Recall@50: 0.9909\n",
      "HitRate@50: 0.9930\n",
      "MAP@50: 0.9126\n",
      "nDCG@50: 0.9482\n",
      "--------------------------------------------------\n",
      "Evaluation on cold user, cold item at top 50:\n",
      "Precision@50: 0.7089\n",
      "Recall@50: 0.7210\n",
      "HitRate@50: 0.7210\n",
      "MAP@50: 0.7139\n",
      "nDCG@50: 0.7159\n",
      "--------------------------------------------------\n",
      "Evaluation on warm user, warm item at top 100:\n",
      "Precision@100: 0.8782\n",
      "Recall@100: 0.9524\n",
      "HitRate@100: 0.9526\n",
      "MAP@100: 0.9250\n",
      "nDCG@100: 0.9360\n",
      "--------------------------------------------------\n",
      "Evaluation on warm user, cold item at top 100:\n",
      "Precision@100: 0.8389\n",
      "Recall@100: 0.8605\n",
      "HitRate@100: 0.8605\n",
      "MAP@100: 0.8479\n",
      "nDCG@100: 0.8515\n",
      "--------------------------------------------------\n",
      "Evaluation on cold user, warm item at top 100:\n",
      "Precision@100: 0.8084\n",
      "Recall@100: 0.9927\n",
      "HitRate@100: 0.9930\n",
      "MAP@100: 0.9125\n",
      "nDCG@100: 0.9481\n",
      "--------------------------------------------------\n",
      "Evaluation on cold user, cold item at top 100:\n",
      "Precision@100: 0.7089\n",
      "Recall@100: 0.7210\n",
      "HitRate@100: 0.7210\n",
      "MAP@100: 0.7139\n",
      "nDCG@100: 0.7159\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation\n",
    "ks = [10, 20, 50, 100]\n",
    "# Evaluate for different k values\n",
    "for k in ks:\n",
    "    results = {}\n",
    "    results['warm user, warm item'] = evaluate_topk_fast(pred_uwarm_iwarm, k=k)\n",
    "    results['warm user, cold item'] = evaluate_topk_fast(pred_uwarm_icold, k=k)\n",
    "    results['cold user, warm item'] = evaluate_topk_fast(pred_ucold_iwarm, k=k)\n",
    "    results['cold user, cold item'] = evaluate_topk_fast(pred_ucold_icold, k=k)\n",
    "\n",
    "    # Print evaluation results\n",
    "    for case, metrics in results.items():\n",
    "        print(f\"Evaluation on {case} at top {k}:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "        print('-' * 50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webmining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
